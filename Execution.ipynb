{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def patch_thresholding(gray,patch_size,const):\n",
    "    \n",
    "    result_mean = np.copy(gray)\n",
    "    \n",
    "    height,width=gray.shape\n",
    "    \n",
    "    origin = math.floor(patch_size/2)\n",
    "    padded = np.pad(gray, origin, mode='constant', constant_values=0)\n",
    "    \n",
    "    index_x = index_y = 0\n",
    "    for i in tqdm(range(origin, height+origin)):\n",
    "        for j in range(origin, width+origin):\n",
    "            patch = padded[i-origin:i+origin+1, j-origin:j+origin+1]\n",
    "            local_mean = np.mean(patch)\n",
    "            \n",
    "            threshold_mean = local_mean - const\n",
    "            \n",
    "            if padded[i,j] >= threshold_mean:\n",
    "               result_mean[index_y, index_x] = 1\n",
    "            else:\n",
    "                result_mean[index_y, index_x] = 0 \n",
    "             \n",
    "            index_x = min(index_x+1, width)\n",
    "        index_y = min(index_y+1, height)\n",
    "        index_x = 0\n",
    "        \n",
    "    normalized_result_mean = np.clip((result_mean - result_mean.min()) / (result_mean.max() - result_mean.min()), 0, 1)\n",
    "    \n",
    "    return normalized_result_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'\\Fundus image' # give directory here\n",
    "images = os.listdir(root)\n",
    "\n",
    "for file_name in images:\n",
    "    full_path = os.path.join(root,file_name)\n",
    "    \n",
    "    image = cv2.imread(full_path,cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    result= patch_thresholding(image,7,5)\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image,cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(result,cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_threshold_image(image,epsilon):\n",
    "    result_mean = result_median = np.zeros_like(image)\n",
    "    \n",
    "    \n",
    "    T1 = int(np.mean(image))\n",
    "    while True:\n",
    "        \n",
    "        G1 = image[image < T1]\n",
    "        G2 = image[image > T1]\n",
    "        \n",
    "        M1 = np.mean(G1)\n",
    "        M2 = np.mean(G2)\n",
    "        \n",
    "        T2 = int((M1+M2)/2)\n",
    "        \n",
    "        if abs(T2-T1) < epsilon:\n",
    "            break\n",
    "        else:\n",
    "            T1 = T2\n",
    "            \n",
    "    _, result_mean = cv2.threshold(image, T2, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    \n",
    "    T2 = np.median(image)    \n",
    "    \n",
    "    _, result_median = cv2.threshold(image, T2, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "    return result_mean,result_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOTTING VEINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = r'\\Fundus image'\n",
    "images = os.listdir(root)\n",
    "\n",
    "for file_name in images:\n",
    "    full_path = os.path.join(root,file_name)\n",
    "    \n",
    "    image = cv2.imread(full_path,cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    result,_ = adaptive_threshold_image(image,5)\n",
    "    \n",
    "    adaptive_thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5, 5)\n",
    "    \n",
    "    _, binary = cv2.threshold(image, 170, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Plot the results side by side\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    axes[0].imshow(image, cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(adaptive_thresh, cmap='gray')\n",
    "    axes[1].set_title('Adaptive Threshold buitin')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(binary, cmap='gray')\n",
    "    axes[2].set_title('basic threshold')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    #break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch_contrast(image):\n",
    "    \n",
    "    min_val = np.percentile(image, 15)\n",
    "    max_val = np.percentile(image, 99)\n",
    "    \n",
    "    stretched_image = np.clip(image, min_val, max_val)\n",
    "    \n",
    "    stretched_image = (stretched_image - min_val) / (max_val - min_val) * 255\n",
    "    \n",
    "    stretched_image = stretched_image.astype(np.uint8)\n",
    "    \n",
    "    return stretched_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = r'\\Fundus image'\n",
    "images = os.listdir(root)\n",
    "\n",
    "subjects = []\n",
    "\n",
    "for i in range(len(images)):\n",
    "    \n",
    "    \n",
    "    full_path = os.path.join(root,images[i])\n",
    "    \n",
    "    print(full_path)\n",
    "    \n",
    "    orignal = cv2.imread(full_path,cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    enhanced = stretch_contrast(orignal)\n",
    "    \n",
    "    _, binary = cv2.threshold(enhanced, 254, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    adaptive_threshold = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    subjects.append(binary)\n",
    "    \n",
    "    #veins = patch_thresholding(enhanced,7,5)\n",
    "    \n",
    "    # Plot the results side by side\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
    "\n",
    "    axes[0].imshow(orignal, cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(enhanced, cmap='gray')\n",
    "    axes[1].set_title('enhanced image')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(binary, cmap='gray')\n",
    "    axes[2].set_title('basic thresholding')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    axes[3].imshow(adaptive_threshold, cmap='gray')\n",
    "    axes[3].set_title('adaptive thresholding')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    #break\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_x = []\n",
    "results_y = []\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    kernel = [\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 0, 0]\n",
    "]\n",
    "\n",
    "    kernel_array = np.array(kernel,dtype=np.uint8)\n",
    "    \n",
    "    eroded_image = cv2.erode(subject, kernel_array, iterations=1)\n",
    "    dilated_image = cv2.dilate(eroded_image, kernel_array, iterations=1)\n",
    "    \n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dilated_image, connectivity=8)\n",
    "\n",
    "    # num_labels: Total number of labels (including background)\n",
    "    # labels: Image where each pixel is assigned a label\n",
    "    # stats: Statistics for each connected component (e.g., area, bounding box)\n",
    "    # centroids: Centroid coordinates for each connected component\n",
    "\n",
    "    largest_label = np.argmax(stats[1:, cv2.CC_STAT_AREA]) + 1\n",
    "\n",
    "    area = stats[largest_label, cv2.CC_STAT_AREA]\n",
    "    centroid = centroids[largest_label].astype(int)\n",
    "    print(f\"Largest connected component: Label={largest_label}, Area={area}, Centroid={centroid}\")\n",
    "\n",
    "    results_x.append(centroids[largest_label][0].astype(int))\n",
    "    results_y.append(centroids[largest_label][1].astype(int))\n",
    "    \n",
    "    largest_area_mask = np.where(labels == largest_label, 255, 0).astype(np.uint8)\n",
    "\n",
    "    labeled_image = cv2.cvtColor(subject, cv2.COLOR_GRAY2BGR)\n",
    "    labeled_image = cv2.applyColorMap((labels * 255 / num_labels).astype('uint8'), cv2.COLORMAP_JET)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
    "\n",
    "    axes[0].imshow(subject, cmap='gray')\n",
    "    axes[0].set_title('thresholded')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "\n",
    "    axes[1].imshow(dilated_image, cmap='gray')\n",
    "    axes[1].set_title('after opening')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    largest_area_image = cv2.bitwise_and(dilated_image, dilated_image, mask=largest_area_mask)\n",
    "    \n",
    "    axes[2].imshow(labeled_image, cmap='gray')\n",
    "    axes[2].set_title('all objects')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    axes[3].imshow(largest_area_image, cmap='gray')\n",
    "    axes[3].set_title('optic-disc')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    #break\n",
    "    \n",
    "print(results_x,results_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r'\\optic_disc_centres.csv')\n",
    "\n",
    "csv_file_names = df.iloc[:, 0].values\n",
    "csv_x = df.iloc[:, 1].values\n",
    "csv_y = df.iloc[:, 2].values\n",
    "\n",
    "for i in range(len(csv_file_names)):\n",
    "    print(csv_file_names[i], csv_x[i],csv_y[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORMANCE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "for i in range(len(results_y)):\n",
    "    error = ( (csv_x[i]-results_x[i])**2 + (csv_y[i]-results_y[i])**2 )**0.5\n",
    "    print(error)\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['File name'] = csv_file_names\n",
    "df['actual_x'] = csv_x\n",
    "df['actual_y'] = csv_y\n",
    "df['Results_x'] = results_x\n",
    "df['Results_y'] = results_y\n",
    "df['Errors'] = errors\n",
    "\n",
    "df.to_csv(r'F:\\NOTES\\Season 3.2\\DIP\\Assignment-2 data\\Assignment-2\\output_file2.csv', index=False)\n",
    "\n",
    "print(\"Data has been written to 'output_file.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
